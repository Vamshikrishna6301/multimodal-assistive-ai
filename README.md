ğŸŒ Project Vision

A safety-first multimodal assistive AI platform designed to empower individuals with physical and motor disabilities by enabling:

ğŸ¤ Hands-free system control

ğŸ§  Context-aware decision making

ğŸ”’ Risk-controlled execution

ğŸ¤ Multimodal interaction (Voice â†’ Gesture â†’ Vision â†’ Emotion)

âš™ Deterministic automation with confirmation safeguards

This system bridges the gap between human intent and digital control in real-world environments.

ğŸ“‚ Complete Project Structure
KRISHNA/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ context_memory.py
â”‚   â”œâ”€â”€ fusion_engine.py
â”‚   â”œâ”€â”€ intent_parser.py
â”‚   â”œâ”€â”€ intent_schema.py
â”‚   â”œâ”€â”€ mode_manager.py
â”‚   â”œâ”€â”€ safety_engine.py
â”‚   â””â”€â”€ safety_rules.py
â”‚
â”œâ”€â”€ execution/
â”‚   â”œâ”€â”€ app_control.py
â”‚   â”œâ”€â”€ executor.py
â”‚   â”œâ”€â”€ file_ops.py
â”‚   â””â”€â”€ keyboard_mouse.py
â”‚
â”œâ”€â”€ voice/
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ mic_stream.py
â”‚   â”œâ”€â”€ stt.py
â”‚   â”œâ”€â”€ tts.py
â”‚   â”œâ”€â”€ vad.py
â”‚   â”œâ”€â”€ voice_loop.py
â”‚   â””â”€â”€ wakeword.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ config.py
â”œâ”€â”€ demo_full_pipeline.py
â”œâ”€â”€ demo_phase2.py
â”œâ”€â”€ direct_record_test.py
â”œâ”€â”€ intent_parser_reference.py
â”œâ”€â”€ INTENT_PATTERNS_ANALYSIS.json
â”œâ”€â”€ main.py
â”œâ”€â”€ mic_test.py
â”œâ”€â”€ raw_stt_stream_test.py
â”œâ”€â”€ raw_stt_test.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ run_phase2_voice.py
â”œâ”€â”€ test_context.py
â”œâ”€â”€ test_parser.py
â”œâ”€â”€ test_phase2_pipeline.py
â”œâ”€â”€ test_safety.py
â”œâ”€â”€ tests_execution.py
â””â”€â”€ tests_phase2.py


ğŸ— System Architecture
Voice / Gesture / Vision / Emotion
              â†“
        Intent Parser
              â†“
        Context Memory
              â†“
        Safety Engine
              â†“
        Fusion Engine
              â†“
        Execution Engine
              â†“
         User Feedback
Design Guarantees

Deterministic logic

Confirmation enforcement

Risk escalation handling

Single safe action execution

Real-time responsiveness

Accessibility-first design

ğŸŸ¢ PHASE 1 â€” Core Intent & Safety Engine

Status: âœ… Complete

ğŸ¯ Goal

Build a deterministic, safety-aware decision engine.

ğŸ”¹ Components
Intent Schema

Structured Intent dataclass

Risk levels (0â€“9)

Confirmation flags

Entities & parameters

Session tracking

Intent Parser

Flexible keyword detection (anywhere in sentence)

Multi-word normalization ("shut down" â†’ "shutdown")

Filler word removal

Target extraction

Structured parameter mapping

Supports:

Commands

Questions

Control instructions

Dictation mode

Unknown fallback

Mode Manager (Finite State Machine)

Modes:

LISTENING

COMMAND

DICTATION

QUESTION

DISABLED

Safety Engine

Risk scoring

Dangerous pattern escalation ("delete all")

Confirmation enforcement

Hard blocking for extreme risk

Context Memory

Multi-step linking

Confirmation retention

Session awareness

Fusion Engine

Combines parsing + safety + context

Handles confirmation state

Generates structured decision objects

Tracks latency

ğŸ§ª Phase 1 Testing
Test Type	Status
Command detection	âœ…
Risk escalation	âœ…
Confirmation loop	âœ…
Cancel flow	âœ…
Hard blocking	âœ…
Mode transitions	âœ…
ğŸ¤ PHASE 2 â€” Real-Time Voice Integration

Status: âœ… Complete

ğŸ¯ Goal

Transform decision engine into real-time assistive voice system.

ğŸ”¹ Technologies Used

faster-whisper (GPU accelerated STT)

PyTorch CUDA

WebRTC VAD

SoundDevice

PyTTSx3

NumPy

Threading

ğŸ”¹ Components
Microphone Stream

16kHz fixed rate

30ms frames

Queue buffering

VAD compatible

Voice Activity Detection (WebRTC)

Balanced aggressiveness tuning

Silence detection

Minimum speech duration threshold

Noise robustness

Speech-to-Text

GPU acceleration

CPU fallback

Beam search optimization

Short audio rejection

Text-to-Speech

Non-blocking

Thread-safe

Offline capable

Real-Time Runtime

Speech segmentation

Silence-based stop logic

Noise filtering

Confirmation voice loop

ğŸ§ª Phase 2 Testing
Scenario	Result
Silence rejection	âœ…
Background noise filtering	âœ…
Natural language flexibility	âœ…
Confirmation handling	âœ…
Cancellation handling	âœ…
Latency stability	âœ…
ğŸŸ¡ PHASE 3 â€” Execution Engine

Status: ğŸš§ In Progress

ğŸ¯ Goal

Connect approved decisions to real OS actions.

Responsibilities

Execute only APPROVED intents

Respect confirmation requirements

Enforce safety locks

Log execution events

Windows OS abstraction (first target)

Planned Functions
open_app(app_name)
search_browser(query)
type_text(text)
close_active_app()
delete_file(path)  # requires confirmation
Tech Stack

subprocess

os

pyautogui

Windows API

Required Test Cases
Command	Expected
open chrome	Chrome launches
search transformers	Browser search executes
type hello	Text typed
delete file	Confirmed deletion only
ğŸ”µ PHASE 4 â€” Vision Integration

Status: ğŸŸ¦ Planned

Features

Screen capture

OCR

Object detection

Scene narration

Tech

OpenCV

Tesseract

YOLOv8

ğŸŸ£ PHASE 5 â€” Advanced Context Engine

Status: ğŸŸ£ Planned

Features

Multi-step memory

Action chaining

Reference resolution graph

Task continuation logic

ğŸŸ  PHASE 6 â€” Gesture Interaction

Status: ğŸŸ  Planned

Features

MediaPipe Hands

Gesture override

Emergency stop

Cursor control

ğŸ”´ PHASE 7 â€” Emotion Awareness

Status: ğŸ”´ Planned

Features

Face emotion detection

Voice stress analysis

Adaptive response tone

Confirmation sensitivity adjustment

ğŸŸ¡ PHASE 8 â€” Multimodal Fusion Core

Status: ğŸŸ¡ Critical Future Phase

Goal

Resolve conflicts between:

Voice

Gesture

Vision

Emotion

Guarantee

Exactly ONE safe action will execute.

ğŸŸ¡ PHASE 9 â€” Adaptive Learning

Status: ğŸŸ¡ Planned

Features

User preference modeling

Personalized shortcuts

Confirmation tolerance adaptation

Usage pattern learning

ğŸŸ¡ PHASE 10 â€” UI & Accessibility Profiles

Status: ğŸŸ¡ Planned

Features

Voice-only mode

Gesture-only mode

Visual feedback dashboard

High-contrast UI

Slow-response mode

Low-motor configuration

ğŸŒ Real-World Impact

Designed for:

Individuals with limited motor control

Hands-free computing environments

Accessibility-focused systems

Safety-sensitive automation

The system prioritizes:

Safety over speed

Determinism over randomness

Confirmation over blind execution

ğŸ Current Status Summary
Phase	Status
Phase 1 â€” Core Engine	âœ… Complete
Phase 2 â€” Voice Runtime	âœ… Complete
Phase 3 â€” Execution Engine	ğŸš§ In Progress
Phase 4 â€” Vision	ğŸŸ¦ Planned
Phase 5 â€” Advanced Context	ğŸŸ£ Planned
Phase 6 â€” Gesture	ğŸŸ  Planned
Phase 7 â€” Emotion	ğŸ”´ Planned
Phase 8 â€” Multimodal Fusion	ğŸŸ¡ Critical
Phase 9 â€” Adaptive Learning	ğŸŸ¡ Planned
Phase 10 â€” UI & Accessibility	ğŸŸ¡ Planned