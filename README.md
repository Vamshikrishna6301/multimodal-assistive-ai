ğŸŒ Project Vision

A safety-first multimodal assistive AI platform designed to empower individuals with physical and motor disabilities by enabling:

ğŸ¤ Hands-free system control

ğŸ§  Context-aware decision making

ğŸ”’ Risk-controlled execution

ğŸ¤ Multimodal interaction (Voice â†’ Gesture â†’ Vision â†’ Emotion)

âš™ Deterministic automation with confirmation safeguards

This system bridges the gap between human intent and digital control in real-world environments.

ğŸ“‚ Complete Project Structure
KRISHNA/
â”‚
â”œâ”€â”€ core/                          # Phase 1 â€” Intent & Safety Core
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ context_memory.py
â”‚   â”œâ”€â”€ fusion_engine.py
â”‚   â”œâ”€â”€ intent_parser.py
â”‚   â”œâ”€â”€ intent_schema.py
â”‚   â”œâ”€â”€ mode_manager.py
â”‚   â”œâ”€â”€ safety_engine.py
â”‚   â”œâ”€â”€ safety_rules.py
â”‚   â””â”€â”€ response_model.py          # UnifiedResponse
â”‚
â”œâ”€â”€ router/                        # Phase 3 â€” Decision Routing
â”‚   â””â”€â”€ decision_router.py
â”‚
â”œâ”€â”€ execution/                     # Phase 3.1 â€” Execution Engine
â”‚   â”œâ”€â”€ execution_engine.py
â”‚   â”œâ”€â”€ dispatcher.py
â”‚   â””â”€â”€ adapters/
â”‚       â”œâ”€â”€ windows_app.py
â”‚       â”œâ”€â”€ windows_browser.py
â”‚       â”œâ”€â”€ windows_keyboard.py
â”‚       â”œâ”€â”€ windows_file.py
â”‚       â””â”€â”€ windows_system.py
â”‚
â”œâ”€â”€ utility/                       # Phase 3.2 â€” Utility Engine
â”‚   â””â”€â”€ utility_engine.py
â”‚
â”œâ”€â”€ knowledge/                     # Phase 3.3 â€” Hybrid Knowledge
â”‚   â”œâ”€â”€ knowledge_engine.py        # Wikipedia
â”‚   â””â”€â”€ llm_engine.py              # TinyLlama (Ollama)
â”‚
â”œâ”€â”€ voice/                         # Phase 2 + Phase 3.5 â€” Runtime
â”‚   â”œâ”€â”€ assistant_runtime.py
â”‚   â”œâ”€â”€ mic_stream.py
â”‚   â”œâ”€â”€ vad.py
â”‚   â”œâ”€â”€ stt.py
â”‚   â”œâ”€â”€ tts.py
â”‚   â””â”€â”€ voice_loop.py
â”‚
â”œâ”€â”€ config.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ tests/                         # Consolidated tests
â”‚   â”œâ”€â”€ test_context.py
â”‚   â”œâ”€â”€ test_parser.py
â”‚   â”œâ”€â”€ test_safety.py
â”‚   â”œâ”€â”€ test_execution.py
â”‚   â””â”€â”€ test_voice_pipeline.py
â”‚
â””â”€â”€ demos/
    â”œâ”€â”€ demo_phase2.py
    â””â”€â”€ demo_full_pipeline.py

ğŸ— System Architecture
Voice / Gesture / Vision / Emotion
              â†“
        Intent Parser
              â†“
        Context Memory
              â†“
        Safety Engine
              â†“
        Fusion Engine
              â†“
        Execution Engine
              â†“
         User Feedback
Design Guarantees

Deterministic logic

Confirmation enforcement

Risk escalation handling

Single safe action execution

Real-time responsiveness

Accessibility-first design

ğŸŸ¢ PHASE 1 â€” Core Intent & Safety Engine

Status: âœ… Complete

ğŸ¯ Goal

Build a deterministic, safety-aware decision engine.

ğŸ”¹ Components
Intent Schema

Structured Intent dataclass

Risk levels (0â€“9)

Confirmation flags

Entities & parameters

Session tracking

Intent Parser

Flexible keyword detection (anywhere in sentence)

Multi-word normalization ("shut down" â†’ "shutdown")

Filler word removal

Target extraction

Structured parameter mapping

Supports:

Commands

Questions

Control instructions

Dictation mode

Unknown fallback

Mode Manager (Finite State Machine)

Modes:

LISTENING

COMMAND

DICTATION

QUESTION

DISABLED

Safety Engine

Risk scoring

Dangerous pattern escalation ("delete all")

Confirmation enforcement

Hard blocking for extreme risk

Context Memory

Multi-step linking

Confirmation retention

Session awareness

Fusion Engine

Combines parsing + safety + context

Handles confirmation state

Generates structured decision objects

Tracks latency

ğŸ§ª Phase 1 Testing
Test Type	Status
Command detection	âœ…
Risk escalation	âœ…
Confirmation loop	âœ…
Cancel flow	âœ…
Hard blocking	âœ…
Mode transitions	âœ…text
ğŸ¤ PHASE 2 â€” Real-Time Voice Integration

Status: âœ… Complete

ğŸ¯ Goal

Transform decision engine into real-time assistive voice system.

ğŸ”¹ Technologies Used

faster-whisper (GPU accelerated STT)

PyTorch CUDA

WebRTC VAD

SoundDevice

PyTTSx3

NumPy

Threading

ğŸ”¹ Components
Microphone Stream

16kHz fixed rate

30ms frames

Queue buffering

VAD compatible

Voice Activity Detection (WebRTC)

Balanced aggressiveness tuning

Silence detection

Minimum speech duration threshold

Noise robustness

Speech-to-Text

GPU acceleration

CPU fallback

Beam search optimization

Short audio rejection

Text-to-Speech

Non-blocking

Thread-safe

Offline capable

Real-Time Runtime

Speech segmentation

Silence-based stop logic

Noise filtering

Confirmation voice loop

ğŸ§ª Phase 2 Testing
Scenario	Result
Silence rejection	âœ…
Background noise filtering	âœ…
Natural language flexibility	âœ…
Confirmation handling	âœ…
Cancellation handling	âœ…
Latency stability	âœ…
ğŸŸ¡ PHASE 3 â€” Execution Engine (Updated with Current Issues)
Status: ğŸš§ In Progress (Runtime Stability Required)
ğŸ¯ Goal

Connect approved decisions to real OS actions in a safe, deterministic, production-ready way.

ğŸ§  Core Responsibilities
1ï¸âƒ£ Execute only APPROVED intents

ExecutionEngine must refuse:

BLOCKED

NEEDS_CONFIRMATION

UNKNOWN

2ï¸âƒ£ Respect Confirmation Requirements

High-risk commands must:

Trigger confirmation in FusionEngine

Only execute after explicit â€œyesâ€

Examples:

shutdown

delete file

close app

restart

3ï¸âƒ£ Enforce Safety Locks

Must prevent:

Dangerous paths (C:, system folders)

Mass delete

Unknown system commands

Empty targets

4ï¸âƒ£ OS Abstraction Layer

ExecutionEngine â†’ Dispatcher â†’ WindowsAdapters

Adapters must isolate OS-level code.

5ï¸âƒ£ Logging (Missing)

Phase 3 must log:

Action

Target

Timestamp

Success / Failure

Error message

(Currently not implemented)

ğŸŸ¢ Planned Functions
open_app(app_name)
search_browser(query)
type_text(text)
close_active_app()
delete_file(path)  # requires confirmation
shutdown()
restart()
ğŸ”´ CURRENT CRITICAL PROBLEM (Phase 3 Runtime Blocking)
Problem: Assistant appears to "get stuck" after first command.
Observed Behavior:

First command works

Assistant responds

After that, system either:

Keeps waiting for audio

Transcribes its own speech

Stops detecting real input

Appears frozen

ğŸ§  ROOT CAUSE

This is NOT an execution bug.

This is a runtime acoustic feedback + speech segmentation issue.

Specifically:

Assistant speaks.

Microphone captures speaker output.

VAD detects it as speech.

STT transcribes assistantâ€™s own voice.

This causes:

Fake inputs ("thank you")

Noise chunks

Unexpected intent triggers

After that, real user speech may not be captured properly.

So it looks like:

System stuck after one command

But actually:

System is processing its own TTS output
ğŸŸ¡ Secondary Runtime Issue

If mic is blocked during speaking and speaking flag does not reset correctly:

Mic stops capturing

No new chunks pushed

System appears frozen

This is a concurrency + state flag issue.

ğŸ”´ Why This Is Important For Phase 3

Phase 3 assumes:

Decision â†’ Execution

But runtime instability means:

Noise â†’ False decision â†’ Execution

So before Phase 3 is considered stable:

Runtime must be stabilized.

ğŸ›  Required Runtime Fixes Before Phase 3 Completion
âœ… 1. Drop audio chunks while assistant speaking

(Not pause mic â€” drop chunks.)

âœ… 2. Increase VAD aggressiveness

Level 3 recommended.

âœ… 3. Add minimum speech duration threshold

Ignore tiny noise bursts.

âœ… 4. Prevent STT from running while speaking

Avoid acoustic feedback loop.

ğŸŸ¡ Execution Engine Maturity Issues

Even after runtime fix, Phase 3 still has:



âŒ Unsupported system control command

Cause: Adapter not mapping correct action/target.

âŒ No execution logging

Need audit layer.

ğŸ§ª Updated Required Test Cases
Execution Tests
Command	Expected
open chrome	Chrome launches
open notepad	Notepad opens
close notepad	Requires confirmation â†’ closes
delete test.txt	Requires confirmation â†’ deletes
shutdown	Requires confirmation â†’ shuts down
restart	Requires confirmation â†’ restarts
delete C:\	BLOCKED
Runtime Stability Tests
Scenario	Expected
Speak 2 commands back-to-back	Both recognized
Assistant speaks	No self-transcription
Say "stop" while speaking	Speech interrupts
Silent environment	No fake triggers
Background fan noise	No false commands
ğŸŸ¢ True Phase 3 Completion Criteria

Phase 3 is only complete when:

âœ” Execution stable
âœ” Confirmation enforced
âœ” Runtime stable
âœ” No echo loop
âœ” No one-command freeze
âœ” No false self-triggering
âœ” OS adapters fully mapped
âœ” Logging implemented
ğŸ”µ PHASE 4 â€” Vision Integration

Status: ğŸŸ¦ Planned

Features

Screen capture

OCR

Object detection

Scene narration

Tech

OpenCV

Tesseract

YOLOv8

ğŸŸ£ PHASE 5 â€” Advanced Context Engine

Status: ğŸŸ£ Planned

Features

Multi-step memory

Action chaining

Reference resolution graph

Task continuation logic

ğŸŸ  PHASE 6 â€” Gesture Interaction

Status: ğŸŸ  Planned

Features

MediaPipe Hands

Gesture override

Emergency stop

Cursor control

ğŸ”´ PHASE 7 â€” Emotion Awareness

Status: ğŸ”´ Planned

Features

Face emotion detection

Voice stress analysis

Adaptive response tone

Confirmation sensitivity adjustment

ğŸŸ¡ PHASE 8 â€” Multimodal Fusion Core

Status: ğŸŸ¡ Critical Future Phase

Goal

Resolve conflicts between:

Voice

Gesture

Vision

Emotion

Guarantee

Exactly ONE safe action will execute.

ğŸŸ¡ PHASE 9 â€” Adaptive Learning

Status: ğŸŸ¡ Planned

Features

User preference modeling

Personalized shortcuts

Confirmation tolerance adaptation

Usage pattern learning

ğŸŸ¡ PHASE 10 â€” UI & Accessibility Profiles

Status: ğŸŸ¡ Planned

Features

Voice-only mode

Gesture-only mode

Visual feedback dashboard

High-contrast UI

Slow-response mode

Low-motor configuration

ğŸŒ Real-World Impact

Designed for:

Individuals with limited motor control

Hands-free computing environments

Accessibility-focused systems

Safety-sensitive automation

The system prioritizes:

Safety over speed

Determinism over randomness

Confirmation over blind execution

ğŸ Current Status Summary
Phase	Status
Phase 1 â€” Core Engine	âœ… Complete
Phase 2 â€” Voice Runtime	âœ… Complete
Phase 3 â€” Execution Engine	ğŸš§ In Progress
Phase 4 â€” Vision	ğŸŸ¦ Planned
Phase 5 â€” Advanced Context	ğŸŸ£ Planned
Phase 6 â€” Gesture	ğŸŸ  Planned
Phase 7 â€” Emotion	ğŸ”´ Planned
Phase 8 â€” Multimodal Fusion	ğŸŸ¡ Critical
Phase 9 â€” Adaptive Learning	ğŸŸ¡ Planned
Phase 10 â€” UI & Accessibility	ğŸŸ¡ Planned