ğŸŒ Project Vision

A safety-first multimodal assistive AI platform designed to empower individuals with physical and motor disabilities by enabling:

ğŸ¤ Hands-free system control

ğŸ§  Context-aware decision making

ğŸ”’ Risk-controlled execution

ğŸ¤ Multimodal interaction (Voice â†’ Gesture â†’ Vision â†’ Emotion)

âš™ Deterministic automation with confirmation safeguards

This system bridges the gap between human intent and digital control in real-world environments.



Voice
â†“
Intent Parser
â†“
Context Memory
â†“
Safety Engine
â†“
Fusion Engine
â†“
Decision Router
â†“
Execution Engine
â†“
(UIA Service / OS Adapters / Utility / Knowledge)
â†“
User Feedback

ğŸ“‚ Complete Project Structure
KRISHNA/
â”‚
â”œâ”€â”€ __pycache__/
â”œâ”€â”€ .cache/
â”‚
â”œâ”€â”€ core/                              # Phase 1 â€” Intent & Safety Core
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ context_memory.py
â”‚   â”œâ”€â”€ fusion_engine.py
â”‚   â”œâ”€â”€ intent_parser.py
â”‚   â”œâ”€â”€ intent_schema.py
â”‚   â”œâ”€â”€ mode_manager.py
â”‚   â”œâ”€â”€ neural_intent_classifier.py
â”‚   â”œâ”€â”€ response_model.py
â”‚   â”œâ”€â”€ safety_engine.py
â”‚   â””â”€â”€ safety_rules.py
â”‚
â”œâ”€â”€ data/
â”‚
â”œâ”€â”€ execution/                         # Phase 3 â€” Execution Layer
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚
â”‚   â”œâ”€â”€ adapters/                      # OS abstraction layer
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ windows_app.py
â”‚   â”‚   â”œâ”€â”€ windows_browser.py
â”‚   â”‚   â”œâ”€â”€ windows_file.py
â”‚   â”‚   â”œâ”€â”€ windows_keyboard.py
â”‚   â”‚   â””â”€â”€ windows_system.py
â”‚   â”‚
â”‚   â”œâ”€â”€ uia_service/                   # ğŸ”¥ NEW â€” External UI Automation Service
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ uia_client.py              # Socket client (used by ExecutionEngine)
â”‚   â”‚   â””â”€â”€ uia_server.py              # Standalone UIA socket server
â”‚   â”‚
â”‚   â”œâ”€â”€ vision/                        # Phase 4 â€” Vision Integration
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ camera_detector.py
â”‚   â”‚   â”œâ”€â”€ event_engine.py
â”‚   â”‚   â”œâ”€â”€ ocr_engine.py
â”‚   â”‚   â”œâ”€â”€ scene_graph_engine.py
â”‚   â”‚   â”œâ”€â”€ scene_memory.py
â”‚   â”‚   â”œâ”€â”€ screen_capture.py
â”‚   â”‚   â”œâ”€â”€ screen_monitoring_engine.py
â”‚   â”‚   â”œâ”€â”€ stabilization_buffer.py
â”‚   â”‚   â”œâ”€â”€ tracking_engine.py
â”‚   â”‚   â”œâ”€â”€ vision_executor.py
â”‚   â”‚   â”œâ”€â”€ vision_mode_controller.py
â”‚   â”‚   â””â”€â”€ vision_query_engine.py
â”‚   â”‚
â”‚   â”œâ”€â”€ dispatcher.py                  # Routes execution to adapters
â”‚   â”œâ”€â”€ execution_logger.py            # Execution audit layer (partial)
â”‚   â”œâ”€â”€ executor.py                    # ğŸ”¥ Main ExecutionEngine
â”‚   â”œâ”€â”€ file_ops.py
â”‚   â””â”€â”€ keyboard_mouse.py
â”‚
â”œâ”€â”€ infrastructure/                    # Production runtime infrastructure
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cache.py
â”‚   â”œâ”€â”€ config_manager.py
â”‚   â”œâ”€â”€ error_handling.py
â”‚   â”œâ”€â”€ health_monitor.py
â”‚   â”œâ”€â”€ logger.py
â”‚   â”œâ”€â”€ persistence.py
â”‚   â”œâ”€â”€ production_logger.py
â”‚   â”œâ”€â”€ system_monitor.py
â”‚   â””â”€â”€ validation.py
â”‚
â”œâ”€â”€ knowledge/                         # Phase 3.3 â€” Knowledge Layer
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ knowledge_engine.py            # Wikipedia
â”‚   â””â”€â”€ llm_engine.py                  # Local LLM (TinyLlama / Ollama)
â”‚
â”œâ”€â”€ logs/
â”‚
â”œâ”€â”€ models/
â”‚
â”œâ”€â”€ phase4_ai_intelligence/
â”‚
â”œâ”€â”€ router/                            # Phase 3 â€” Decision Router
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â””â”€â”€ decision_router.py
â”‚
â”œâ”€â”€ tests/
â”‚
â”œâ”€â”€ utility/                           # Phase 3.2 â€” Utility Engine
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â””â”€â”€ utility_engine.py
â”‚
â”œâ”€â”€ voice/                             # Phase 2 â€” Voice Runtime
â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”œâ”€â”€ assistant_runtime.py
â”‚   â”œâ”€â”€ mic_stream.py
â”‚   â”œâ”€â”€ stt.py
â”‚   â”œâ”€â”€ tts.py
â”‚   â”œâ”€â”€ vad.py
â”‚   â”œâ”€â”€ voice_loop.py
â”‚   â””â”€â”€ wakeword.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ config.py
â”œâ”€â”€ main.py                            # ğŸ”¥ Main system entrypoint
â”‚
â”œâ”€â”€ debug_tools/                       # (Recommended grouping)
â”‚   â”œâ”€â”€ camera_index_test.py
â”‚   â”œâ”€â”€ check_active_window.py
â”‚   â”œâ”€â”€ debug_startup.py
â”‚   â”œâ”€â”€ debug_startup2.py
â”‚   â””â”€â”€ direct_record_test.py
â”‚
â”œâ”€â”€ demos/
â”‚   â”œâ”€â”€ demo_phase2.py
â”‚   â”œâ”€â”€ demo_full_pipeline.py
â”‚   â”œâ”€â”€ demo_phase4_camera_visual.py
â”‚   â”œâ”€â”€ demo_phase4_live_corrected.py
â”‚   â”œâ”€â”€ demo_phase4_text_visual.py
â”‚   â””â”€â”€ demo_phase4_vision.py
â”‚
â””â”€â”€ README.md

ğŸ— System Architecture
Voice / Gesture / Vision / Emotion
              â†“
        Intent Parser
              â†“
        Context Memory
              â†“
        Safety Engine
              â†“
        Fusion Engine
              â†“
        Execution Engine
              â†“
         User Feedback
Design Guarantees

Deterministic logic

Confirmation enforcement

Risk escalation handling

Single safe action execution

Real-time responsiveness

Accessibility-first design

ğŸŸ¢ PHASE 1 â€” Core Intent & Safety Engine

Status: âœ… Complete

ğŸ¯ Goal

Build a deterministic, safety-aware decision engine.

ğŸ”¹ Components
Intent Schema

Structured Intent dataclass

Risk levels (0â€“9)

Confirmation flags

Entities & parameters

Session tracking

Intent Parser

Flexible keyword detection (anywhere in sentence)

Multi-word normalization ("shut down" â†’ "shutdown")

Filler word removal

Target extraction

Structured parameter mapping

Supports:

Commands

Questions

Control instructions

Dictation mode

Unknown fallback

Mode Manager (Finite State Machine)

Modes:

LISTENING

COMMAND

DICTATION

QUESTION

DISABLED

Safety Engine

Risk scoring

Dangerous pattern escalation ("delete all")

Confirmation enforcement

Hard blocking for extreme risk

Context Memory

Multi-step linking

Confirmation retention

Session awareness

Fusion Engine

Combines parsing + safety + context

Handles confirmation state

Generates structured decision objects

Tracks latency

ğŸ§ª Phase 1 Testing
Test Type	Status
Command detection	âœ…
Risk escalation	âœ…
Confirmation loop	âœ…
Cancel flow	âœ…
Hard blocking	âœ…
Mode transitions	âœ…text
ğŸ¤ PHASE 2 â€” Real-Time Voice Integration

Status: âœ… Complete

ğŸ¯ Goal

Transform decision engine into real-time assistive voice system.

ğŸ”¹ Technologies Used

faster-whisper (GPU accelerated STT)

PyTorch CUDA

WebRTC VAD

SoundDevice

PyTTSx3

NumPy

Threading

ğŸ”¹ Components
Microphone Stream

16kHz fixed rate

30ms frames

Queue buffering

VAD compatible

Voice Activity Detection (WebRTC)

Balanced aggressiveness tuning

Silence detection

Minimum speech duration threshold

Noise robustness

Speech-to-Text

GPU acceleration

CPU fallback

Beam search optimization

Short audio rejection

Text-to-Speech

Non-blocking

Thread-safe

Offline capable

Real-Time Runtime

Speech segmentation

Silence-based stop logic

Noise filtering

Confirmation voice loop

ğŸ§ª Phase 2 Testing
Scenario	Result
Silence rejection	âœ…
Background noise filtering	âœ…
Natural language flexibility	âœ…
Confirmation handling	âœ…
Cancellation handling	âœ…
Latency stability	âœ…
ğŸŸ¡ PHASE 3 â€” Execution Engine (Updated with Current Issues)
Status: ğŸš§ In Progress (Runtime Stability Required)
ğŸ¯ Goal

Connect approved decisions to real OS actions in a safe, deterministic, production-ready way.

ğŸ§  Core Responsibilities
1ï¸âƒ£ Execute only APPROVED intents

ExecutionEngine must refuse:

BLOCKED

NEEDS_CONFIRMATION

UNKNOWN

2ï¸âƒ£ Respect Confirmation Requirements

High-risk commands must:

Trigger confirmation in FusionEngine

Only execute after explicit â€œyesâ€

Examples:

shutdown

delete file

close app

restart

3ï¸âƒ£ Enforce Safety Locks

Must prevent:

Dangerous paths (C:, system folders)

Mass delete

Unknown system commands

Empty targets

4ï¸âƒ£ OS Abstraction Layer

ExecutionEngine â†’ Dispatcher â†’ WindowsAdapters

Adapters must isolate OS-level code.

5ï¸âƒ£ Logging (Missing)

Phase 3 must log:

Action

Target

Timestamp

Success / Failure

Error message

(Currently not implemented)

ğŸŸ¢ Planned Functions
open_app(app_name)
search_browser(query)
type_text(text)
close_active_app()
delete_file(path)  # requires confirmation
shutdown()
restart()
ğŸ”´ CURRENT CRITICAL PROBLEM (Phase 3 Runtime Blocking)
Problem: Assistant appears to "get stuck" after first command.
Observed Behavior:

First command works

Assistant responds

After that, system either:

Keeps waiting for audio

Transcribes its own speech

Stops detecting real input

Appears frozen

ğŸ§  ROOT CAUSE

This is NOT an execution bug.

This is a runtime acoustic feedback + speech segmentation issue.

Specifically:

Assistant speaks.

Microphone captures speaker output.

VAD detects it as speech.

STT transcribes assistantâ€™s own voice.

This causes:

Fake inputs ("thank you")

Noise chunks

Unexpected intent triggers

After that, real user speech may not be captured properly.

So it looks like:

System stuck after one command

But actually:

System is processing its own TTS output
ğŸŸ¡ Secondary Runtime Issue

If mic is blocked during speaking and speaking flag does not reset correctly:

Mic stops capturing

No new chunks pushed

System appears frozen

This is a concurrency + state flag issue.

ğŸ”´ Why This Is Important For Phase 3

Phase 3 assumes:

Decision â†’ Execution

But runtime instability means:

Noise â†’ False decision â†’ Execution

So before Phase 3 is considered stable:

Runtime must be stabilized.

ğŸ›  Required Runtime Fixes Before Phase 3 Completion
âœ… 1. Drop audio chunks while assistant speaking

(Not pause mic â€” drop chunks.)

âœ… 2. Increase VAD aggressiveness

Level 3 recommended.

âœ… 3. Add minimum speech duration threshold

Ignore tiny noise bursts.

âœ… 4. Prevent STT from running while speaking

Avoid acoustic feedback loop.

ğŸŸ¡ Execution Engine Maturity Issues

Even after runtime fix, Phase 3 still has:

âŒ Close Notepad Not Working

Cause: WindowsSystemAdapter.handle() incomplete.

âŒ Unsupported system control command

Cause: Adapter not mapping correct action/target.

âŒ No execution logging

Need audit layer.

ğŸ§ª Updated Required Test Cases
Execution Tests
Command	Expected
open chrome	Chrome launches
open notepad	Notepad opens
close notepad	Requires confirmation â†’ closes
delete test.txt	Requires confirmation â†’ deletes
shutdown	Requires confirmation â†’ shuts down
restart	Requires confirmation â†’ restarts
delete C:\	BLOCKED
Runtime Stability Tests
Scenario	Expected
Speak 2 commands back-to-back	Both recognized
Assistant speaks	No self-transcription
Say "stop" while speaking	Speech interrupts
Silent environment	No fake triggers
Background fan noise	No false commands




ğŸ†• Major Architecture Upgrade (Phase 3 Final Form)

During runtime stabilization and UI integration, the architecture was significantly upgraded.

ğŸ”¥ External UIA Service (New)

UI automation was extracted into a separate socket-based service:

Assistant â†’ UIAClient (socket) â†’ UIA Server â†’ pywinauto
Why This Was Done

Previously:

UIA ran inside main assistant thread

Thread locks caused freezes

UI traversal blocked voice loop

Deadlocks occurred

Now:

UIA runs as isolated service

No cross-thread COM conflicts

No UI freeze blocking voice

Clean separation of concerns

ğŸ–± Semantic UI Control (Now Working)

The assistant now supports:

âœ… Screen Reading

"What is on my screen?"

Returns:

Active window name

Interactive elements (indexed)

Element type + name

Works across:

Notepad

File Explorer

VS Code

Chrome

Windows Settings

Any UIA-compatible Windows app

âœ… Click by Index

"Click 5"
"Click number 3"

Works reliably.

âœ… Click by Name (New)

"Click edit"
"Click file"
"Click view"
"Click bold"

Supported via:

action = CLICK_NAME
parameters = {"name": "edit"}

Fixed routing bug where CLICK_NAME was not reaching ExecutionEngine.

ğŸ§  Router Architecture Fix (Critical Fix)

Previously:

if action in EXECUTION_ACTIONS:

This caused:

CLICK_NAME not routed

Unsupported action errors

Now:

All non-utility / non-knowledge actions
â†’ go directly to ExecutionEngine

This prevents future routing bugs.

ğŸ”Œ UIA Communication Protocol (Final Form)
Server

Raw TCP socket

JSON payload

No HTTP

No Flask

No requests library

Client

Raw socket

Sends JSON

Receives JSON

Decodes safely

Fix resolved:

BadStatusLine
Connection aborted
Unsupported action type
ğŸ¤ Runtime Stability Issues (Important)

The assistant previously appeared to "freeze" after one command.

ğŸ” Root Cause

Not execution bug.

Acoustic feedback loop:

Assistant speaks

Microphone captures speaker audio

VAD detects as speech

STT transcribes assistantâ€™s own voice

Fake intents generated

This created illusion of freeze.

ğŸ›  Required Runtime Hardening (Still Recommended)

Before full production:

Drop mic frames while speaking

Increase VAD aggressiveness (Level 3)

Enforce minimum speech duration

Prevent STT while TTS active

Add echo cancellation (future improvement)

ğŸŸ¢ Phase 3 â€” Execution Engine (Current State)
âœ… Now Working

UIA read screen

Click by index

Click by name

OS abstraction layer

Confirmation enforcement

Risk validation

Decision validation

Router stability

External UIA isolation

âš  Still Needs Improvement

Execution logging not fully implemented

Some Windows adapters incomplete

Close Notepad occasionally inconsistent

No persistent action audit log

No retry policy for UI failures

No timeout protection on UIA service

ğŸŸ¢ Phase 4 â€” Vision Integration

Status: âœ… Stable

Includes:

Screen OCR

YOLOv8 object detection

Scene graph reasoning

Detection stabilization

Mode-based behavior

Camera tracking

Screen monitoring

Now fully integrated with voice runtime.

ğŸ§ª Updated Testing Status
UIA Tests
Command	Status
Read screen	âœ…
Click by index	âœ…
Click by name	âœ…
Cross-application support	âœ…
Runtime Stability
Scenario	Status
Back-to-back commands	âš  Needs improvement
Echo suppression	âš  Partial
Interrupt while speaking	âœ…
Silence handling	âœ…
Voice
â†“
Intent Parser
â†“
Context Memory
â†“
Safety Engine
â†“
Fusion Engine
â†“
Decision Router
â†“
Execution Engine
â†“
(UIA Service / OS Adapters / Utility / Knowledge)
â†“
User Feedback