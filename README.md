ğŸŒ Project Vision

A safety-first multimodal assistive AI platform designed to empower individuals with physical and motor disabilities by enabling:

ğŸ¤ Hands-free system control

ğŸ§  Context-aware decision making

ğŸ”’ Risk-controlled execution

ğŸ¤ Multimodal interaction (Voice â†’ Gesture â†’ Vision â†’ Emotion)

âš™ Deterministic automation with confirmation safeguards

This system bridges the gap between human intent and digital control in real-world environments.

ğŸ“‚ Complete Project Structure
KRISHNA/
â”‚
â”œâ”€â”€ core/                          # Phase 1 â€” Intent & Safety Core
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ context_memory.py
â”‚   â”œâ”€â”€ fusion_engine.py
â”‚   â”œâ”€â”€ intent_parser.py
â”‚   â”œâ”€â”€ intent_schema.py
â”‚   â”œâ”€â”€ mode_manager.py
â”‚   â”œâ”€â”€ safety_engine.py
â”‚   â”œâ”€â”€ safety_rules.py
â”‚   â””â”€â”€ response_model.py          # UnifiedResponse
â”‚
â”œâ”€â”€ router/                        # Phase 3 â€” Decision Routing
â”‚   â””â”€â”€ decision_router.py
â”‚
â”œâ”€â”€ execution/                     # Phase 3.1 â€” Execution Engine
â”‚   â”œâ”€â”€ execution_engine.py
â”‚   â”œâ”€â”€ dispatcher.py
â”‚   â””â”€â”€ adapters/
â”‚       â”œâ”€â”€ windows_app.py
â”‚       â”œâ”€â”€ windows_browser.py
â”‚       â”œâ”€â”€ windows_keyboard.py
â”‚       â”œâ”€â”€ windows_file.py
â”‚       â””â”€â”€ windows_system.py
â”‚
â”œâ”€â”€ utility/                       # Phase 3.2 â€” Utility Engine
â”‚   â””â”€â”€ utility_engine.py
â”‚
â”œâ”€â”€ knowledge/                     # Phase 3.3 â€” Hybrid Knowledge
â”‚   â”œâ”€â”€ knowledge_engine.py        # Wikipedia
â”‚   â””â”€â”€ llm_engine.py              # TinyLlama (Ollama)
â”‚
â”œâ”€â”€ voice/                         # Phase 2 + Phase 3.5 â€” Runtime
â”‚   â”œâ”€â”€ assistant_runtime.py
â”‚   â”œâ”€â”€ mic_stream.py
â”‚   â”œâ”€â”€ vad.py
â”‚   â”œâ”€â”€ stt.py
â”‚   â”œâ”€â”€ tts.py
â”‚   â””â”€â”€ voice_loop.py
â”‚
â”œâ”€â”€ config.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ tests/                         # Consolidated tests
â”‚   â”œâ”€â”€ test_context.py
â”‚   â”œâ”€â”€ test_parser.py
â”‚   â”œâ”€â”€ test_safety.py
â”‚   â”œâ”€â”€ test_execution.py
â”‚   â””â”€â”€ test_voice_pipeline.py
â”‚
â””â”€â”€ demos/
    â”œâ”€â”€ demo_phase2.py
    â””â”€â”€ demo_full_pipeline.py

ğŸ— System Architecture
Voice / Gesture / Vision / Emotion
              â†“
        Intent Parser
              â†“
        Context Memory
              â†“
        Safety Engine
              â†“
        Fusion Engine
              â†“
        Execution Engine
              â†“
         User Feedback
Design Guarantees

Deterministic logic

Confirmation enforcement

Risk escalation handling

Single safe action execution

Real-time responsiveness

Accessibility-first design

ğŸŸ¢ PHASE 1 â€” Core Intent & Safety Engine

Status: âœ… Complete

ğŸ¯ Goal

Build a deterministic, safety-aware decision engine.

ğŸ”¹ Components
Intent Schema

Structured Intent dataclass

Risk levels (0â€“9)

Confirmation flags

Entities & parameters

Session tracking

Intent Parser

Flexible keyword detection (anywhere in sentence)

Multi-word normalization ("shut down" â†’ "shutdown")

Filler word removal

Target extraction

Structured parameter mapping

Supports:

Commands

Questions

Control instructions

Dictation mode

Unknown fallback

Mode Manager (Finite State Machine)

Modes:

LISTENING

COMMAND

DICTATION

QUESTION

DISABLED

Safety Engine

Risk scoring

Dangerous pattern escalation ("delete all")

Confirmation enforcement

Hard blocking for extreme risk

Context Memory

Multi-step linking

Confirmation retention

Session awareness

Fusion Engine

Combines parsing + safety + context

Handles confirmation state

Generates structured decision objects

Tracks latency

ğŸ§ª Phase 1 Testing
Test Type	Status
Command detection	âœ…
Risk escalation	âœ…
Confirmation loop	âœ…
Cancel flow	âœ…
Hard blocking	âœ…
Mode transitions	âœ…text
ğŸ¤ PHASE 2 â€” Real-Time Voice Integration

Status: âœ… Complete

ğŸ¯ Goal

Transform decision engine into real-time assistive voice system.

ğŸ”¹ Technologies Used

faster-whisper (GPU accelerated STT)

PyTorch CUDA

WebRTC VAD

SoundDevice

PyTTSx3

NumPy

Threading

ğŸ”¹ Components
Microphone Stream

16kHz fixed rate

30ms frames

Queue buffering

VAD compatible

Voice Activity Detection (WebRTC)

Balanced aggressiveness tuning

Silence detection

Minimum speech duration threshold

Noise robustness

Speech-to-Text

GPU acceleration

CPU fallback

Beam search optimization

Short audio rejection

Text-to-Speech

Non-blocking

Thread-safe

Offline capable

Real-Time Runtime

Speech segmentation

Silence-based stop logic

Noise filtering

Confirmation voice loop

ğŸ§ª Phase 2 Testing
Scenario	Result
Silence rejection	âœ…
Background noise filtering	âœ…
Natural language flexibility	âœ…
Confirmation handling	âœ…
Cancellation handling	âœ…
Latency stability	âœ…
ğŸŸ¢ PHASE 3 â€” Execution Engine

Status: ğŸŸ¡ Execution Complete | Runtime Hardening Ongoing

ğŸ¯ Goal

Safely connect approved intents to real OS actions with confirmation, safety enforcement, and structured audit logging.

âœ… Completed
1ï¸âƒ£ Approved-Only Execution

ExecutionEngine runs only:

APPROVED intents
Rejects:

BLOCKED

NEEDS_CONFIRMATION

UNKNOWN

2ï¸âƒ£ Confirmation Enforcement

High-risk actions require explicit â€œyesâ€:

close app

delete file

shutdown

restart

Runtime handles confirmation lifecycle correctly.

3ï¸âƒ£ Safety Locks

Prevents:

Dangerous paths (e.g., C:\)

Empty targets

Unsupported commands

Low-confidence unknown inputs

4ï¸âƒ£ OS Abstraction

Clean architecture:

ExecutionEngine
   â†“
Dispatcher
   â†“
Windows Adapters

Execution layer contains no OS-specific code.

5ï¸âƒ£ Structured Audit Logging âœ…

Implemented ExecutionLogger.

Logs:

timestamp

action

target

success/failure

error_code

Stored in:

execution_logs.json

Audit system complete.

6ï¸âƒ£ Context + App Stack

Implemented:

close it

go back

switch app

Uses app stack instead of single last_app.

Context updates only after successful execution.

ğŸŸ¡ Runtime Stability (Remaining)

Issue:
Assistant may transcribe its own speech (echo loop).

Needed:

Drop mic audio while speaking

Prevent STT during TTS

Stronger VAD

Minimum speech threshold

This is runtime hardening, not execution failure.

ğŸ Phase 3 Completion Status

âœ” Execution stable
âœ” Confirmation enforced
âœ” Safety enforced
âœ” App stack implemented
âœ” Logging implemented
âœ” Audit layer complete
ğŸŸ¡ Runtime echo control pending
ğŸ”µ PHASE 4 â€” Vision Integration

Status: ğŸŸ¦ Planned

Features

Screen capture

OCR

Object detection

Scene narration

Tech

OpenCV

Tesseract

YOLOv8

ğŸŸ£ PHASE 5 â€” Advanced Context Engine

Status: ğŸŸ£ Planned

Features

Multi-step memory

Action chaining

Reference resolution graph

Task continuation logic

ğŸŸ  PHASE 6 â€” Gesture Interaction

Status: ğŸŸ  Planned

Features

MediaPipe Hands

Gesture override

Emergency stop

Cursor control

ğŸ”´ PHASE 7 â€” Emotion Awareness

Status: ğŸ”´ Planned

Features

Face emotion detection

Voice stress analysis

Adaptive response tone

Confirmation sensitivity adjustment

ğŸŸ¡ PHASE 8 â€” Multimodal Fusion Core

Status: ğŸŸ¡ Critical Future Phase

Goal

Resolve conflicts between:

Voice

Gesture

Vision

Emotion

Guarantee

Exactly ONE safe action will execute.

ğŸŸ¡ PHASE 9 â€” Adaptive Learning

Status: ğŸŸ¡ Planned

Features

User preference modeling

Personalized shortcuts

Confirmation tolerance adaptation

Usage pattern learning

ğŸŸ¡ PHASE 10 â€” UI & Accessibility Profiles

Status: ğŸŸ¡ Planned

Features

Voice-only mode

Gesture-only mode

Visual feedback dashboard

High-contrast UI

Slow-response mode

Low-motor configuration

ğŸŒ Real-World Impact

Designed for:

Individuals with limited motor control

Hands-free computing environments

Accessibility-focused systems

Safety-sensitive automation

The system prioritizes:

Safety over speed

Determinism over randomness

Confirmation over blind execution

ğŸ Current Status Summary
Phase	Status
Phase 1 â€” Core Engine	âœ… Complete
Phase 2 â€” Voice Runtime	âœ… Complete
Phase 3 â€” Execution Engine	ğŸš§ In Progress
Phase 4 â€” Vision	ğŸŸ¦ Planned
Phase 5 â€” Advanced Context	ğŸŸ£ Planned
Phase 6 â€” Gesture	ğŸŸ  Planned
Phase 7 â€” Emotion	ğŸ”´ Planned
Phase 8 â€” Multimodal Fusion	ğŸŸ¡ Critical
Phase 9 â€” Adaptive Learning	ğŸŸ¡ Planned
Phase 10 â€” UI & Accessibility	ğŸŸ¡ Planned